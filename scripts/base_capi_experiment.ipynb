{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e2f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'capi'...\n",
      "remote: Enumerating objects: 48, done.\u001b[K\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 48 (delta 23), reused 45 (delta 20), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (48/48), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tcfuji/capi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49df42f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/capi\n"
     ]
    }
   ],
   "source": [
    "cd capi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46bcd4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch.optim import Adam\n",
      "\n",
      "from capi.agents import Agent\n",
      "from capi.games import Game\n",
      "from capi.models import NN\n",
      "from capi.trainers import Trainer\n",
      "\n",
      "\"\"\"\n",
      "Seeds:\n",
      "837\n",
      "450\n",
      "330\n",
      "512\n",
      "869\n",
      "431\n",
      "891\n",
      "473\n",
      "624\n",
      "695\n",
      "\"\"\"\n",
      "\n",
      "seed = 869\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\"--num_items\", type=int, default=5)\n",
      "    parser.add_argument(\"--num_utterances\", type=int, default=5)\n",
      "    parser.add_argument(\"--hidden_size\", type=int, default=256)\n",
      "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
      "    parser.add_argument(\"--num_samples\", type=int, default=10_000)\n",
      "    parser.add_argument(\"--epsilon\", type=float, default=1 / 10)\n",
      "    parser.add_argument(\"--policy_weight\", type=float, default=1 / 100)\n",
      "    parser.add_argument(\"--num_episodes\", type=int, default=500)\n",
      "    parser.add_argument(\"--write_every\", type=int, default=10)\n",
      "    parser.add_argument(\"--directory\", type=str, default=\"results\")\n",
      "    parser.add_argument(\"--jobnum\", type=int, default=0)\n",
      "    parser.add_argument(\"--strict_type_check\", type=bool, default=False)\n",
      "    args = parser.parse_args()\n",
      "    if args.strict_type_check:\n",
      "        os.environ[\"strict_type_check\"] = \"1\"\n",
      "    else:\n",
      "        os.environ[\"strict_type_check\"] = \"0\"\n",
      "    input_size = 2 * args.num_items + 2 * args.num_utterances\n",
      "    nn = NN(input_size, args.hidden_size, args.num_items, args.num_utterances)\n",
      "    opt = Adam(nn.parameters(), lr=args.lr)\n",
      "    g = Game(args.num_items, args.num_utterances)\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    agent = Agent(\n",
      "        args.num_items,\n",
      "        args.num_utterances,\n",
      "        nn,\n",
      "        opt,\n",
      "        args.num_samples,\n",
      "        args.epsilon,\n",
      "        args.policy_weight,\n",
      "        device\n",
      "    )\n",
      "    torch.manual_seed(seed)\n",
      "    trainer = Trainer(g, agent, 'base', args.directory)\n",
      "    trainer.run(args.num_episodes, args.write_every, seed)\n"
     ]
    }
   ],
   "source": [
    "cat scripts/interface_base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1800ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 193/2000 [16:52<2:38:03,  5.25s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-594f8974e09b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/capi/capi/trainers.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_episodes, write_every, seed)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwrite_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/capi/capi/trainers.py\u001b[0m in \u001b[0;36mplay_episode\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mprescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dynamics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/capi/capi/agents.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, s, train)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0maction_dynamics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dynamics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# Induced distributions over private information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mnext_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Next public belief states in tensor repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_dists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/capi/capi/agents.py\u001b[0m in \u001b[0;36mnext_distributions\u001b[0;34m(self, state, prescriptions)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mnorm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mnext_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         assert_joint_probability(\n\u001b[1;32m    365\u001b[0m             \u001b[0mnext_distributions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "from capi.agents import Agent\n",
    "from capi.games import Game\n",
    "from capi.models import NN\n",
    "from capi.trainers import Trainer\n",
    "\n",
    "\"\"\"\n",
    "Seeds:\n",
    "837\n",
    "450\n",
    "330\n",
    "512\n",
    "869\n",
    "431\n",
    "891\n",
    "473\n",
    "624\n",
    "695\n",
    "\"\"\"\n",
    "\n",
    "seed = 869\n",
    "\n",
    "\n",
    "num_items = 5\n",
    "num_utterances = 5\n",
    "hidden_size = 256\n",
    "lr = 1e-4\n",
    "num_samples = 10_000\n",
    "epsilon = 1 / 10\n",
    "policy_weight = 1 / 10\n",
    "num_episodes = 2000\n",
    "write_every = 100\n",
    "directory = \"results\"\n",
    "jobnum = 0\n",
    "\n",
    "os.environ[\"strict_type_check\"] = \"0\"\n",
    "input_size = 2 * num_items + 2 * num_utterances\n",
    "nn = NN(input_size, hidden_size, num_items, num_utterances)\n",
    "opt = Adam(nn.parameters(), lr=lr)\n",
    "g = Game(num_items, num_utterances)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = Agent(\n",
    "    num_items,\n",
    "    num_utterances,\n",
    "    nn,\n",
    "    opt,\n",
    "    num_samples,\n",
    "    epsilon,\n",
    "    policy_weight,\n",
    "    device\n",
    ")\n",
    "torch.manual_seed(seed)\n",
    "trainer = Trainer(g, agent, 'base', directory)\n",
    "trainer.run(num_episodes, write_every, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270449f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
